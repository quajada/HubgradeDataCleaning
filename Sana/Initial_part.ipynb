{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5986f166-5d7f-4429-8b4a-81c51b59aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a90e12-6d4b-46bf-9cc6-e1943bd13fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction.dummy_data_extractor import extract_dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bfd49f-46b3-498a-852b-7571f2a2958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "master_table = extract_dummy_data(\"dummy_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1715b50e-fdb5-4eff-834f-1d7defdb11b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             pointID unit dqType  \\\n",
      "0  @p:dmc_All:r:2ddf07d5-ef59ca94 DMC Building 1 ...   °C  Nulls   \n",
      "1  @p:dmc_All:r:2ddf07d5-ef59ca94 DMC Building 1 ...   °C  Nulls   \n",
      "\n",
      "                     dqStart      dqDuration   pointInterval  \\\n",
      "0  2023-03-12 01:05:00+04:00 1 days 11:10:00 0 days 00:05:00   \n",
      "1  2023-03-19 01:10:00+04:00 0 days 23:30:00 0 days 00:05:00   \n",
      "\n",
      "                          features  \\\n",
      "0  [p:dmc_All:r:2de337c0-72b69972]   \n",
      "1  [p:dmc_All:r:2de337c0-72b69972]   \n",
      "\n",
      "                                                 his  \n",
      "0                                  DMC Building 1...  \n",
      "1                                  DMC Building 1...  \n"
     ]
    }
   ],
   "source": [
    "print(master_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b24181-8f4b-4b01-a8c3-348596a941b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_data = master_table['his']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9113a8-fdab-4118-bede-9abd5335c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                    DMC Building 1...\n",
      "1                                    DMC Building 1...\n",
      "Name: his, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(his_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4971cd1f-fd58-4638-a59b-4d0ed3faccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['ts'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5656\\2652814227.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[0mlength_of_missing_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m  \u001b[1;31m# example value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mdata_logging_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# example value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m# Call the forecasting function with these parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mforecast_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprophet_forecasting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'his'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_of_missing_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_logging_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdqStart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m# Check the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5656\\2652814227.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, length_of_missing_data, data_logging_interval, dqStart)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mall\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mIndex\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \"\"\"\n\u001b[0;32m     21\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_dummy_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dummy_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"his\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Tag and filter rows with missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mmt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5866\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5867\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5870\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5873\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['ts'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "def prophet_forecasting(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    \"\"\"\n",
    "    Function to perform time series forecasting using Prophet.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame, input data with columns ['ts', 'temp', 'new_point']\n",
    "    - length_of_missing_data: int, length of missing data\n",
    "    - data_logging_interval: int, data logging interval\n",
    "    - dqStart: not used in the function but kept for consistency with the original signature\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with predictions for all rows with missing columns. Index names as ts.\n",
    "    \"\"\"\n",
    "    df = extract_dummy_data(\"dummy_data\")\n",
    "    df = df.at[0, \"his\"]\n",
    "    mt = df.set_index([\"ts\"])\n",
    "\n",
    "    # Tag and filter rows with missing\n",
    "    mt[\"status\"] = mt.isna().any(axis=1)\n",
    "    mt_predict = mt[mt[\"status\"] == 1]\n",
    "    X_predict = mt_predict.iloc[:, 0:1]\n",
    "\n",
    "    # Filtered master table\n",
    "    mt_train = mt.dropna()\n",
    "\n",
    "    # Separate data for temperature\n",
    "    df_temp = mt_train[['temp']].reset_index().rename(columns={'ts': 'ds', 'temp': 'y'})\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df_temp['ds'] = df_temp['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Calculate periods based on length_of_missing_data and data_logging_interval\n",
    "    periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_temp, test_temp = train_test_split(df_temp, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Initialize Prophet model with tuned hyperparameters\n",
    "    model_temp = Prophet(seasonality_mode='additive', interval_width=0.95, changepoint_prior_scale=0.00001)\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(train_temp)\n",
    "\n",
    "    # Create future DataFrame for temp\n",
    "    future_temp = model_temp.make_future_dataframe(periods=periods, freq=f'{data_logging_interval}T')\n",
    "\n",
    "    # Predict the future values for temp\n",
    "    forecast_temp = model_temp.predict(future_temp)\n",
    "\n",
    "    # Compute RMSE for temp\n",
    "    predicted_temp = forecast_temp['yhat'].values[-len(test_temp):]\n",
    "    rmse_temp = np.sqrt(mean_squared_error(test_temp['y'], predicted_temp))\n",
    "\n",
    "    # Print RMSE value for temp\n",
    "    print(f\"RMSE for temp: {rmse_temp}\")\n",
    "\n",
    "    # Making predictions on the same data or new data\n",
    "    X_predict = X_predict.dropna()  # Remove rows with NaN values in 'ds'\n",
    "    predict_temp = model_temp.predict(X_predict.rename(columns={X_predict.columns[0]: 'ds'}))\n",
    "\n",
    "    df_temp_pred = pd.DataFrame(data=predict_temp['yhat'].values, index=X_predict.index, columns=['temp_pred'])\n",
    "\n",
    "    df = df_temp_pred\n",
    "\n",
    "    # Print the head of the resulting DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Sample data creation\n",
    "data = {\n",
    "    'ts': pd.date_range(start='2023-01-01', periods=100, freq='D'),\n",
    "    'temp': np.random.randn(100),\n",
    "    'new_point': np.random.randn(100)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introducing some NaNs to simulate missing data\n",
    "df.loc[10:20, 'temp'] = np.nan\n",
    "\n",
    "# Converting to the expected input format\n",
    "df['his'] = df.apply(lambda x: pd.DataFrame([{'ts': x['ts'], 'temp': x['temp'], 'new_point': x['new_point']}]), axis=1)\n",
    "\n",
    "# Define the values for length_of_missing_data and data_logging_interval\n",
    "length_of_missing_data = 400  # example value\n",
    "data_logging_interval = 1  # example value\n",
    "\n",
    "# Call the forecasting function with these parameters\n",
    "forecast_df = prophet_forecasting(pd.DataFrame([{'his': df}]), length_of_missing_data, data_logging_interval, dqStart=None)\n",
    "\n",
    "# Check the results\n",
    "print(forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30171eb-2ed7-4275-8025-8991c07beb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
