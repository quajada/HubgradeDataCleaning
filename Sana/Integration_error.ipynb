{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168d64c5-90dc-4a4f-912f-d61dad39c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9706a999-ba87-4cfc-80e9-1de2bbce5720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "master_table = extract_dummy_data(\"dummy_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb8236ca-6f4e-44b5-ace0-ea2d6eca9e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "\n",
    "# Extract the relevant dataframe from 'master_table'\n",
    "df = master_table.at[1, \"his\"]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Keep only the first two columns\n",
    "df = df.iloc[:, :2]\n",
    "\n",
    "# renaming columns\n",
    "df.columns = ['ds', 'temp']\n",
    "\n",
    "# Remove ' Dubai' from the datetime strings\n",
    "df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "# Convert the 'ds' column to datetime format\n",
    "df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1ff72e25-8f40-4751-8f29-2ade037ac8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where datetime parsing failed\n",
    "df = df.dropna(subset=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f4deed07-aa94-49ee-b945-b0baf1be9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean temperature column and convert to numeric\n",
    "df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "046d028c-1403-4103-acfb-558453fd0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for convenience\n",
    "df.columns = ['ds', 'y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4c198ddf-7ebb-4f61-91cc-585a084f4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for temperature\n",
    "df_temp = df.copy()\n",
    "\n",
    "# Ensure 'ds' column is timezone-naive\n",
    "df_temp['ds'] = df_temp['ds'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58715213-4111-41d7-9c12-25bf04dc18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Prophet models with tuned hyperparameters\n",
    "model_temp = Prophet(seasonality_mode='additive',     # Adjust based on data exploration\n",
    "                     interval_width=0.95,              # Adjust prediction interval if needed\n",
    "                     changepoint_prior_scale=0.01)    # Tune based on data patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eca30293-be2e-42a2-96ad-eb5ca7d6b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x1e61bbc5690>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the models\n",
    "model_temp.fit(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3ff6ca8e-a817-42c1-bcc6-1188d5510921",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89bbb4c6-20fb-4fd6-965f-e1e26a6da571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 23:30:00')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bb90ac54-ec76-4c61-973b-6ea979986024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ad25700-f599-4bae-b205-9b7dae477d77",
   "metadata": {},
   "outputs": [],
   "source": [
    " # number of predictions\n",
    "samples = int(length_of_missing_data/data_logging_interval) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74b909a2-80db-484a-82ef-a633ddd8d2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1da2986a-3f02-4ee3-8ee2-6ad8b52416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future DataFrames for both temp and new_point (next 200 samples, assuming 5-minute intervals)\n",
    "future_temp = model_temp.make_future_dataframe(periods=samples, freq='5T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2e391eda-4d33-404c-b5cd-8186b75242bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the future values\n",
    "forecast_temp = model_temp.predict(future_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3bc514d0-72dd-4934-85a4-e8665199dc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>daily</th>\n",
       "      <th>daily_lower</th>\n",
       "      <th>daily_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-14 21:10:00</td>\n",
       "      <td>24.367781</td>\n",
       "      <td>23.883961</td>\n",
       "      <td>25.342836</td>\n",
       "      <td>24.367781</td>\n",
       "      <td>24.367781</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.264977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.632758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-14 21:15:00</td>\n",
       "      <td>24.368370</td>\n",
       "      <td>23.924441</td>\n",
       "      <td>25.364407</td>\n",
       "      <td>24.368370</td>\n",
       "      <td>24.368370</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.610346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-14 21:20:00</td>\n",
       "      <td>24.368959</td>\n",
       "      <td>23.856130</td>\n",
       "      <td>25.376344</td>\n",
       "      <td>24.368959</td>\n",
       "      <td>24.368959</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.218976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.587935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14 21:25:00</td>\n",
       "      <td>24.369548</td>\n",
       "      <td>23.812498</td>\n",
       "      <td>25.270631</td>\n",
       "      <td>24.369548</td>\n",
       "      <td>24.369548</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.565586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-14 21:30:00</td>\n",
       "      <td>24.370137</td>\n",
       "      <td>23.814294</td>\n",
       "      <td>25.274879</td>\n",
       "      <td>24.370137</td>\n",
       "      <td>24.370137</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.173219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.543357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>2023-03-20 00:20:00</td>\n",
       "      <td>22.253753</td>\n",
       "      <td>21.036540</td>\n",
       "      <td>22.826916</td>\n",
       "      <td>21.677905</td>\n",
       "      <td>22.751828</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.938378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>2023-03-20 00:25:00</td>\n",
       "      <td>22.251469</td>\n",
       "      <td>21.078549</td>\n",
       "      <td>22.822481</td>\n",
       "      <td>21.669657</td>\n",
       "      <td>22.752692</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>-0.322072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.929398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>2023-03-20 00:30:00</td>\n",
       "      <td>22.249185</td>\n",
       "      <td>21.040391</td>\n",
       "      <td>22.794423</td>\n",
       "      <td>21.661408</td>\n",
       "      <td>22.753320</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>-0.328717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.920469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2023-03-20 00:35:00</td>\n",
       "      <td>22.246901</td>\n",
       "      <td>21.055972</td>\n",
       "      <td>22.771148</td>\n",
       "      <td>21.654381</td>\n",
       "      <td>22.753235</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>-0.335356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.911545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2023-03-20 00:40:00</td>\n",
       "      <td>22.244617</td>\n",
       "      <td>20.883930</td>\n",
       "      <td>22.766236</td>\n",
       "      <td>21.648790</td>\n",
       "      <td>22.753151</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>-0.342035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.902583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds      trend  yhat_lower  yhat_upper  trend_lower  \\\n",
       "0    2023-03-14 21:10:00  24.367781   23.883961   25.342836    24.367781   \n",
       "1    2023-03-14 21:15:00  24.368370   23.924441   25.364407    24.368370   \n",
       "2    2023-03-14 21:20:00  24.368959   23.856130   25.376344    24.368959   \n",
       "3    2023-03-14 21:25:00  24.369548   23.812498   25.270631    24.369548   \n",
       "4    2023-03-14 21:30:00  24.370137   23.814294   25.274879    24.370137   \n",
       "...                  ...        ...         ...         ...          ...   \n",
       "1475 2023-03-20 00:20:00  22.253753   21.036540   22.826916    21.677905   \n",
       "1476 2023-03-20 00:25:00  22.251469   21.078549   22.822481    21.669657   \n",
       "1477 2023-03-20 00:30:00  22.249185   21.040391   22.794423    21.661408   \n",
       "1478 2023-03-20 00:35:00  22.246901   21.055972   22.771148    21.654381   \n",
       "1479 2023-03-20 00:40:00  22.244617   20.883930   22.766236    21.648790   \n",
       "\n",
       "      trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
       "0       24.367781        0.264977              0.264977              0.264977   \n",
       "1       24.368370        0.241976              0.241976              0.241976   \n",
       "2       24.368959        0.218976              0.218976              0.218976   \n",
       "3       24.369548        0.196038              0.196038              0.196038   \n",
       "4       24.370137        0.173219              0.173219              0.173219   \n",
       "...           ...             ...                   ...                   ...   \n",
       "1475    22.751828       -0.315375             -0.315375             -0.315375   \n",
       "1476    22.752692       -0.322072             -0.322072             -0.322072   \n",
       "1477    22.753320       -0.328717             -0.328717             -0.328717   \n",
       "1478    22.753235       -0.335356             -0.335356             -0.335356   \n",
       "1479    22.753151       -0.342035             -0.342035             -0.342035   \n",
       "\n",
       "         daily  daily_lower  daily_upper  multiplicative_terms  \\\n",
       "0     0.264977     0.264977     0.264977                   0.0   \n",
       "1     0.241976     0.241976     0.241976                   0.0   \n",
       "2     0.218976     0.218976     0.218976                   0.0   \n",
       "3     0.196038     0.196038     0.196038                   0.0   \n",
       "4     0.173219     0.173219     0.173219                   0.0   \n",
       "...        ...          ...          ...                   ...   \n",
       "1475 -0.315375    -0.315375    -0.315375                   0.0   \n",
       "1476 -0.322072    -0.322072    -0.322072                   0.0   \n",
       "1477 -0.328717    -0.328717    -0.328717                   0.0   \n",
       "1478 -0.335356    -0.335356    -0.335356                   0.0   \n",
       "1479 -0.342035    -0.342035    -0.342035                   0.0   \n",
       "\n",
       "      multiplicative_terms_lower  multiplicative_terms_upper       yhat  \n",
       "0                            0.0                         0.0  24.632758  \n",
       "1                            0.0                         0.0  24.610346  \n",
       "2                            0.0                         0.0  24.587935  \n",
       "3                            0.0                         0.0  24.565586  \n",
       "4                            0.0                         0.0  24.543357  \n",
       "...                          ...                         ...        ...  \n",
       "1475                         0.0                         0.0  21.938378  \n",
       "1476                         0.0                         0.0  21.929398  \n",
       "1477                         0.0                         0.0  21.920469  \n",
       "1478                         0.0                         0.0  21.911545  \n",
       "1479                         0.0                         0.0  21.902583  \n",
       "\n",
       "[1480 rows x 16 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6034ff56-9014-4a4b-b0e0-e428889e05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n",
      "C:\\Users\\syounas\\AppData\\Local\\Temp\\ipykernel_19424\\4232964390.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
      "C:\\Users\\syounas\\AppData\\Local\\Temp\\ipykernel_19424\\4232964390.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
      "C:\\Users\\syounas\\AppData\\Local\\Temp\\ipykernel_19424\\4232964390.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['temp'] = df['temp'].str.extract('(\\d+\\.\\d+)').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            ds       temp new_point\n",
      "0    2023-03-14 21:10:00+04:00  24.269638    33.13%\n",
      "1    2023-03-14 21:15:00+04:00  24.269638    33.13%\n",
      "2    2023-03-14 21:20:00+04:00  24.269638    33.13%\n",
      "3    2023-03-14 21:25:00+04:00  24.269638    33.13%\n",
      "4    2023-03-14 21:30:00+04:00  24.269638    33.13%\n",
      "...                        ...        ...       ...\n",
      "1195 2023-03-19 00:45:00+04:00  22.633480    29.43%\n",
      "1196 2023-03-19 00:50:00+04:00  22.633480    30.55%\n",
      "1197 2023-03-19 00:55:00+04:00  22.633480    30.51%\n",
      "1198 2023-03-19 01:00:00+04:00  22.633480    30.51%\n",
      "1199 2023-03-19 01:05:00+04:00  22.633480    30.51%\n",
      "\n",
      "[1197 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Column ds has timezone specified, which is not supported. Remove timezone.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m Prophet()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fit the model with training data\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_df_prophet)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Make future predictions for the test set\u001b[39;00m\n\u001b[0;32m     48\u001b[0m future \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_future_dataframe(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_df), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\prophet\\forecaster.py:1217\u001b[0m, in \u001b[0;36mProphet.fit\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProphet object can only be fit once. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1215\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstantiate a new object.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1217\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1218\u001b[0m initial_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_initial_params(model_inputs\u001b[38;5;241m.\u001b[39mK)\n\u001b[0;32m   1220\u001b[0m dat \u001b[38;5;241m=\u001b[39m dataclasses\u001b[38;5;241m.\u001b[39masdict(model_inputs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\prophet\\forecaster.py:1135\u001b[0m, in \u001b[0;36mProphet.preprocess\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataframe has less than 2 non-NaN rows.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pd\u001b[38;5;241m.\u001b[39mSeries(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique(), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39msort_values()\n\u001b[1;32m-> 1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_dataframe(history, initialize_scales\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_auto_seasonalities()\n\u001b[0;32m   1137\u001b[0m seasonal_features, prior_scales, component_cols, modes \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_all_seasonality_features(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory))\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\prophet\\forecaster.py:289\u001b[0m, in \u001b[0;36mProphet.setup_dataframe\u001b[1;34m(self, df, initialize_scales)\u001b[0m\n\u001b[0;32m    287\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn ds has timezone specified, which is not supported. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemove timezone.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound NaN in column ds.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Column ds has timezone specified, which is not supported. Remove timezone."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "# Assuming 'extract_dummy_data' function extracts data into 'master_table'\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "\n",
    "# Extract the relevant dataframe from 'master_table'\n",
    "df = master_table.at[1, \"his\"]\n",
    "\n",
    "# Reset index and drop NA values\n",
    "df.reset_index(inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.columns = ['ds', 'temp', 'new_point']\n",
    "\n",
    "# Remove ' Dubai' from the datetime strings\n",
    "df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "# Convert the 'ds' column to datetime format\n",
    "df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "# Extract numeric temperature values\n",
    "df['temp'] = df['temp'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
    "\n",
    "# Print the DataFrame to check\n",
    "print(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(df) * 0.8)  # 80% for training\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "# Prepare the dataframe with required column names for Prophet\n",
    "train_df_prophet = train_df[['ds', 'temp']].copy()\n",
    "train_df_prophet.rename(columns={'temp': 'y'}, inplace=True)  # Rename 'temp' to 'y'\n",
    "\n",
    "# Initialize Prophet model\n",
    "model = Prophet()\n",
    "\n",
    "# Fit the model with training data\n",
    "model.fit(train_df_prophet)\n",
    "\n",
    "# Make future predictions for the test set\n",
    "future = model.make_future_dataframe(periods=len(test_df), freq='H')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "y_true = test_df['temp'].values\n",
    "y_pred = forecast['yhat'].values[-len(test_df):]\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Save test set to CSV\n",
    "test_df.to_csv(r'C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\Data\\test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8900d3a-8e3a-4264-9054-b9cc0682a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                ds                  temp\n",
      "0  2023-03-14T21:10:00+04:00 Dubai  24.269638061523438°C\n",
      "1  2023-03-14T21:15:00+04:00 Dubai  24.269638061523438°C\n",
      "2  2023-03-14T21:20:00+04:00 Dubai  24.269638061523438°C\n",
      "3  2023-03-14T21:25:00+04:00 Dubai  24.269638061523438°C\n",
      "4  2023-03-14T21:30:00+04:00 Dubai  24.269638061523438°C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "from fbprophet import Prophet\n",
    "import pandas as pd\n",
    "\n",
    "def fProphet(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    df: df used for training set (from SS)\n",
    "    length_of_missing_data: interval length of missing data (from SS)\n",
    "    data_logging_interval: data logging interval - called from the hisDQInterval tag on the point (from SS)\n",
    "\n",
    "    Output\n",
    "    forecasts_df: dataframe with predictions for the period missing data. Index names as ts, values column named as \"v0\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename the first column as \"target\"\n",
    "    new_column_name = \"target\"\n",
    "    df = df.rename(columns={df.columns[0]: new_column_name})\n",
    "\n",
    "    # Keep only the history BEFORE the start of the data quality issue, since this is a statistical model not ML model\n",
    "    df = df[df.index < dqStart]\n",
    "\n",
    "    # Format the df to Prophet format\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={df.columns[0]: 'ds', df.columns[1]: \"y\"})\n",
    "\n",
    "    # Number of predictions\n",
    "    horizon = int(length_of_missing_data / data_logging_interval) + 1\n",
    "\n",
    "    # Frequency (Prophet will infer this from the data, but can be specified)\n",
    "    freq = f'{data_logging_interval.total_seconds() / 3600}H'\n",
    "\n",
    "    # Initialize and fit the Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(df)\n",
    "\n",
    "    # Make a dataframe to hold predictions\n",
    "    future = model.make_future_dataframe(periods=horizon, freq=freq)\n",
    "\n",
    "    # Make predictions\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Filter out the predictions corresponding to the missing data period\n",
    "    forecasts_df = forecast[['ds', 'yhat']].tail(horizon)\n",
    "    forecasts_df = forecasts_df.rename(columns={\"ds\": \"timestamp\", \"yhat\": \"dynamicOptimizedTheta\"})\n",
    "    forecasts_df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "    return forecasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106f2b5-105d-4e57-ac89-f1d628418bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = r'C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\Data\\Train_1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Rename columns for convenience\n",
    "data.columns = ['ts', 'temp']\n",
    "\n",
    "# Convert 'ts' column to datetime and handle timezone offset\n",
    "data['ts'] = pd.to_datetime(data['ts'].str.replace(' Dubai', ''), errors='coerce')\n",
    "# Drop rows where datetime parsing failed\n",
    "data = data.dropna(subset=['ts'])\n",
    "\n",
    "# Clean temperature column and convert to numeric\n",
    "data['temp'] = data['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "# Separate data for temperature\n",
    "df_temp = data[['ts', 'temp']].rename(columns={'ts': 'ds', 'temp': 'y'})\n",
    "\n",
    "# Ensure 'ds' column is timezone-naive\n",
    "df_temp['ds'] = df_temp['ds'].dt.tz_localize(None)\n",
    "\n",
    "# Initialize Prophet models with tuned hyperparameters\n",
    "model_temp = Prophet(seasonality_mode='additive',     # Adjust based on data exploration\n",
    "                     interval_width=0.95,              # Adjust prediction interval if needed\n",
    "                     changepoint_prior_scale=0.01)    # Tune based on data patterns\n",
    "\n",
    "# Fit the models\n",
    "model_temp.fit(df_temp)\n",
    "\n",
    "# Create future DataFrames for both temp and new_point (next 200 samples, assuming 5-minute intervals)\n",
    "future_temp = model_temp.make_future_dataframe(periods=200, freq='5T')\n",
    "\n",
    "# Predict the future values\n",
    "forecast_temp = model_temp.predict(future_temp)\n",
    "\n",
    "# Calculate RMSE for the last 200 points in the training data\n",
    "forecast_train = model_temp.predict(df_temp)\n",
    "y_true = df_temp['y'].values[-200:]\n",
    "y_pred = forecast_train['yhat'].values[-200:]\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(f\"RMSE for the last 200 training points: {rmse}\")\n",
    "\n",
    "# Format the predicted 'ds' column to \"2023-03-11T08:20:00+04:00 Dubai\"\n",
    "forecast_temp['ds'] = forecast_temp['ds'].dt.tz_localize('UTC').dt.tz_convert('Asia/Dubai').dt.strftime('%Y-%m-%dT%H:%M:%S%z') + ' Dubai'\n",
    "\n",
    "# Save only the predicted 200 future values (ds and yhat columns) to a CSV file\n",
    "output_path = r'C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\Data\\predictions.csv'\n",
    "forecast_temp[['ds', 'yhat']].tail(200).to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
