{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41967c42-2508-4597-8732-b31c00480bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            ds                  temp new_point\n",
      "0    2023-03-14 21:10:00+04:00  24.269638061523438°C    33.13%\n",
      "1    2023-03-14 21:15:00+04:00  24.269638061523438°C    33.13%\n",
      "2    2023-03-14 21:20:00+04:00  24.269638061523438°C    33.13%\n",
      "3    2023-03-14 21:25:00+04:00  24.269638061523438°C    33.13%\n",
      "4    2023-03-14 21:30:00+04:00  24.269638061523438°C    33.13%\n",
      "...                        ...                   ...       ...\n",
      "1195 2023-03-19 00:45:00+04:00  22.633480072021484°C    29.43%\n",
      "1196 2023-03-19 00:50:00+04:00  22.633480072021484°C    30.55%\n",
      "1197 2023-03-19 00:55:00+04:00  22.633480072021484°C    30.51%\n",
      "1198 2023-03-19 01:00:00+04:00  22.633480072021484°C    30.51%\n",
      "1199 2023-03-19 01:05:00+04:00  22.633480072021484°C    30.51%\n",
      "\n",
      "[1197 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n",
      "C:\\Users\\syounas\\AppData\\Local\\Temp\\ipykernel_3076\\3611807380.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
      "C:\\Users\\syounas\\AppData\\Local\\Temp\\ipykernel_3076\\3611807380.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "# Extract dummy data\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "\n",
    "# Select the relevant DataFrame\n",
    "df = master_table.at[1, \"his\"]\n",
    "\n",
    "# Reset index and drop NA values\n",
    "df.reset_index(inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['ds', 'temp', 'new_point']\n",
    "\n",
    "# Remove ' Dubai' from the datetime strings\n",
    "df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "# Convert the 'ds' column to datetime format\n",
    "df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "# Print the DataFrame to check\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "233f78fd-74e0-4986-bdfe-4f4d8c7dc500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m df_new_point \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_point\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_point\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Ensure 'ds' column is timezone-naive\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m df_new_point[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_new_point[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Initialize Prophet models with tuned hyperparameters\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:6204\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6198\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6201\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6202\u001b[0m ):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:608\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "import pytz\n",
    "\n",
    "# Extract dummy data\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "\n",
    "# Select the relevant DataFrame and make a deep copy to avoid SettingWithCopyWarning\n",
    "df = master_table.at[1, \"his\"].copy()\n",
    "\n",
    "# Reset index and drop NA values\n",
    "df.reset_index(inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['ts', 'temp', 'new_point']\n",
    "\n",
    "# Remove ' Dubai' from the datetime strings using .loc to avoid SettingWithCopyWarning\n",
    "df.loc[:, 'ts'] = df['ts'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "# Convert the 'ds' column to datetime format using .loc to avoid SettingWithCopyWarning\n",
    "df.loc[:, 'ts'] = pd.to_datetime(df['ts'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "# Clean temperature column and convert to numeric\n",
    "df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "# Clean percentage column and convert to numeric\n",
    "df['new_point'] = df['new_point'].str.replace('%', '').astype(float)\n",
    "\n",
    "# Separate data for temperature and new_point\n",
    "df_temp = df[['ts', 'temp']].rename(columns={'ts': 'ds', 'temp': 'y'})\n",
    "df_new_point = df[['ts', 'new_point']].rename(columns={'ts': 'ds', 'new_point': 'y'})\n",
    "\n",
    "# Ensure 'ds' column is timezone-naive\n",
    "df_temp['ds'] = df_temp['ds'].dt.tz_localize(None)\n",
    "df_new_point['ds'] = df_new_point['ds'].dt.tz_localize(None)\n",
    "\n",
    "# Initialize Prophet models with tuned hyperparameters\n",
    "model_temp = Prophet(seasonality_mode='additive', interval_width=0.95, changepoint_prior_scale=0.01)\n",
    "model_new_point = Prophet(seasonality_mode='additive', interval_width=0.95, changepoint_prior_scale=0.01)\n",
    "\n",
    "# Fit the models\n",
    "model_temp.fit(df_temp)\n",
    "model_new_point.fit(df_new_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "531e75a2-07f8-4fa0-855e-9e71725c11ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ts'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     81\u001b[0m dqStart \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-03-12 01:05:00+04:00\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m fprophet(df, length_of_missing_data, data_logging_interval, dqStart)\n",
      "Cell \u001b[1;32mIn[78], line 19\u001b[0m, in \u001b[0;36mfprophet\u001b[1;34m(df, length_of_missing_data, data_logging_interval, dqStart)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfprophet\u001b[39m(df, length_of_missing_data, data_logging_interval, dqStart):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Filter data before dqStart\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Dubai\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Reset index and drop NA values\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ts'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract dummy data\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "\n",
    "# Select the relevant DataFrame and make a deep copy to avoid SettingWithCopyWarning\n",
    "df = master_table.at[1, \"his\"].copy()\n",
    "# keep only the history BEFORE the start of the data quality issue, since this is a statistical model not ML model\n",
    "\n",
    "length_of_missing_data = 400\n",
    "data_logging_interval = 1\n",
    "\n",
    "def fprophet(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    # Filter data before dqStart\n",
    "    df['ts'] = df['ts'].str.replace(' Dubai', '', regex=False)\n",
    "    \n",
    "    # Reset index and drop NA values\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.columns = ['ts', 'temp', 'new_point']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = pd.to_datetime(df['ts'], format=\"%Y-%m-%dT%H:%M:%S%z\", errors='coerce')\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Clean percentage column and convert to numeric\n",
    "    df['new_point'] = df['new_point'].str.replace('%', '').astype(float)\n",
    "\n",
    "    # Drop rows where datetime conversion failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Separate data for temperature and new_point\n",
    "    df_temp = df[['ds', 'temp']].rename(columns={'temp': 'y'})\n",
    "    df_new_point = df[['ds', 'new_point']].rename(columns={'new_point': 'y'})\n",
    "\n",
    "    # Initialize Prophet models with tuned hyperparameters\n",
    "    model_temp = Prophet(seasonality_mode='additive', interval_width=0.95, changepoint_prior_scale=0.001)\n",
    "    model_new_point = Prophet(seasonality_mode='additive', interval_width=0.95, changepoint_prior_scale=0.001)\n",
    "\n",
    "    # Fit the models\n",
    "    model_temp.fit(df_temp)\n",
    "    model_new_point.fit(df_new_point)\n",
    "\n",
    "    # Create future DataFrames for both temp and new_point (next n_pred samples, assuming 5-minute intervals)\n",
    "    n_pred = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    future_temp = model_temp.make_future_dataframe(periods=n_pred, freq='5T')\n",
    "    future_new_point = model_new_point.make_future_dataframe(periods=n_pred, freq='5T')\n",
    "\n",
    "    # Predict the future values\n",
    "    forecast_temp = model_temp.predict(future_temp)\n",
    "    forecast_new_point = model_new_point.predict(future_new_point)\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals_temp = df_temp['y'] - forecast_temp['yhat'][:len(df_temp)]\n",
    "    residuals_new_point = df_new_point['y'] - forecast_new_point['yhat'][:len(df_new_point)]\n",
    "\n",
    "    # Compute RMSE for temp\n",
    "    actual_temp = df_temp['y'].values\n",
    "    predicted_temp = forecast_temp['yhat'].values[-n_pred:]\n",
    "    rmse_temp = np.sqrt(mean_squared_error(actual_temp[-n_pred:], predicted_temp))\n",
    "    print(f\"RMSE for temp: {rmse_temp}\")\n",
    "\n",
    "    # Compute RMSE for new_point\n",
    "    actual_new_point = df_new_point['y'].values\n",
    "    predicted_new_point = forecast_new_point['yhat'].values[-n_pred:]\n",
    "    rmse_new_point = np.sqrt(mean_squared_error(actual_new_point[-n_pred:], predicted_new_point))\n",
    "    print(f\"RMSE for new_point: {rmse_new_point}\")\n",
    "\n",
    "# Example usage\n",
    "dqStart = pd.Timestamp('2023-03-12 01:05:00+04:00')\n",
    "fprophet(df, length_of_missing_data, data_logging_interval, dqStart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76dcbbf-ae71-40c8-bdbb-50dbc3791d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
