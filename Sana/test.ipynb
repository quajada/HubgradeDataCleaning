{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e20a41-1cd1-417e-aa5d-f2d8b58e1202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f479209-798d-4156-aca4-f92f05876cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pointID', 'unit', 'dqType', 'dqStart', 'dqDuration', 'pointInterval',\n",
       "       'features', 'his'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebc6992-9d51-42ea-a504-01ad2fc87f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMC Building 1 Data Quality Tests Dup of AHU_04_B1 Return Air Temp</th>\n",
       "      <th>DMC Building 1 Data Quality Tests New-Point</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-14T21:10:00+04:00 Dubai</th>\n",
       "      <td>24.269638061523438°C</td>\n",
       "      <td>33.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14T21:15:00+04:00 Dubai</th>\n",
       "      <td>24.269638061523438°C</td>\n",
       "      <td>33.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14T21:20:00+04:00 Dubai</th>\n",
       "      <td>24.269638061523438°C</td>\n",
       "      <td>33.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14T21:25:00+04:00 Dubai</th>\n",
       "      <td>24.269638061523438°C</td>\n",
       "      <td>33.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14T21:30:00+04:00 Dubai</th>\n",
       "      <td>24.269638061523438°C</td>\n",
       "      <td>33.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-19T00:45:00+04:00 Dubai</th>\n",
       "      <td>22.633480072021484°C</td>\n",
       "      <td>29.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-19T00:50:00+04:00 Dubai</th>\n",
       "      <td>22.633480072021484°C</td>\n",
       "      <td>30.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-19T00:55:00+04:00 Dubai</th>\n",
       "      <td>22.633480072021484°C</td>\n",
       "      <td>30.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-19T01:00:00+04:00 Dubai</th>\n",
       "      <td>22.633480072021484°C</td>\n",
       "      <td>30.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-19T01:05:00+04:00 Dubai</th>\n",
       "      <td>22.633480072021484°C</td>\n",
       "      <td>30.51%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DMC Building 1 Data Quality Tests Dup of AHU_04_B1 Return Air Temp  \\\n",
       "ts                                                                                                   \n",
       "2023-03-14T21:10:00+04:00 Dubai                               24.269638061523438°C                   \n",
       "2023-03-14T21:15:00+04:00 Dubai                               24.269638061523438°C                   \n",
       "2023-03-14T21:20:00+04:00 Dubai                               24.269638061523438°C                   \n",
       "2023-03-14T21:25:00+04:00 Dubai                               24.269638061523438°C                   \n",
       "2023-03-14T21:30:00+04:00 Dubai                               24.269638061523438°C                   \n",
       "...                                                                            ...                   \n",
       "2023-03-19T00:45:00+04:00 Dubai                               22.633480072021484°C                   \n",
       "2023-03-19T00:50:00+04:00 Dubai                               22.633480072021484°C                   \n",
       "2023-03-19T00:55:00+04:00 Dubai                               22.633480072021484°C                   \n",
       "2023-03-19T01:00:00+04:00 Dubai                               22.633480072021484°C                   \n",
       "2023-03-19T01:05:00+04:00 Dubai                               22.633480072021484°C                   \n",
       "\n",
       "                                DMC Building 1 Data Quality Tests New-Point  \n",
       "ts                                                                           \n",
       "2023-03-14T21:10:00+04:00 Dubai                                      33.13%  \n",
       "2023-03-14T21:15:00+04:00 Dubai                                      33.13%  \n",
       "2023-03-14T21:20:00+04:00 Dubai                                      33.13%  \n",
       "2023-03-14T21:25:00+04:00 Dubai                                      33.13%  \n",
       "2023-03-14T21:30:00+04:00 Dubai                                      33.13%  \n",
       "...                                                                     ...  \n",
       "2023-03-19T00:45:00+04:00 Dubai                                      29.43%  \n",
       "2023-03-19T00:50:00+04:00 Dubai                                      30.55%  \n",
       "2023-03-19T00:55:00+04:00 Dubai                                      30.51%  \n",
       "2023-03-19T01:00:00+04:00 Dubai                                      30.51%  \n",
       "2023-03-19T01:05:00+04:00 Dubai                                      30.51%  \n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb59c93-4bbc-4d60-b561-251632d3211e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c5ba8-4632-42b4-891c-e6930426b125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947eeb87-d2ab-41f9-ad21-b6db7fa9a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n",
      "09:14:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:14:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.503415\n",
      "2023-03-19 01:15:00  22.493035\n",
      "2023-03-19 01:20:00  22.482317\n",
      "2023-03-19 01:25:00  22.471234\n",
      "2023-03-19 01:30:00  22.459765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "def facebook_pred(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Initialize Prophet model with tuned hyperparameters\n",
    "    model_temp = Prophet(seasonality_mode='additive',  # Adjust based on data exploration\n",
    "                         interval_width=0.95,          # Adjust prediction interval if needed\n",
    "                         changepoint_prior_scale=0.01) # Tune based on data patterns\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df)\n",
    "\n",
    "    # Number of predictions\n",
    "    samples = int(length_of_missing_data / data_logging_interval) + 1\n",
    "\n",
    "    # Create future DataFrame\n",
    "    future_temp = model_temp.make_future_dataframe(periods=samples, freq='5T')\n",
    "\n",
    "    # Predict the future values\n",
    "    forecast_temp = model_temp.predict(future_temp)\n",
    "\n",
    "    # Convert dq_start to timezone-naive\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "\n",
    "    # Ensure 'ds' column in forecast_temp is timezone-naive\n",
    "    forecast_temp['ds'] = forecast_temp['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = forecast_temp[forecast_temp['ds'] >= dq_start][['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = facebook_pred(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf2a77f-4e40-41cb-9aa2-694519dc012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.641504\n",
      "2023-03-19 01:15:00  22.641407\n",
      "2023-03-19 01:20:00  22.652977\n",
      "2023-03-19 01:25:00  22.648750\n",
      "2023-03-19 01:30:00  22.621050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    # Initialize XGBoost model\n",
    "    model_temp = xgb.XGBRegressor()\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dddbe6c-7367-4a46-8a38-927ee6b002a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.747757\n",
      "2023-03-19 01:15:00  22.740808\n",
      "2023-03-19 01:20:00  22.694866\n",
      "2023-03-19 01:25:00  22.684923\n",
      "2023-03-19 01:30:00  22.666439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    ## Initialize XGBoost model with parameters to reduce noise\n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=100,   # Number of boosting rounds\n",
    "        max_depth=3,        # Maximum depth of each tree\n",
    "        learning_rate=0.1,  # Learning rate\n",
    "        min_child_weight=1, # Minimum sum of instance weight needed in a child\n",
    "        subsample=0.8,      # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        objective='reg:squarederror'  # Objective function for regression task\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e2b8d1e-2b78-4138-8955-91b4fc4d1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.807035\n",
      "2023-03-19 01:15:00  22.807035\n",
      "2023-03-19 01:20:00  22.807035\n",
      "2023-03-19 01:25:00  22.807035\n",
      "2023-03-19 01:30:00  22.807035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart).tz_convert('Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    # Initialize XGBoost model with parameters to reduce noise\n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=90,   # Number of boosting rounds\n",
    "        max_depth=1,        # Maximum depth of each tree\n",
    "        learning_rate=0.1,  # Learning rate\n",
    "        min_child_weight=1, # Minimum sum of instance weight needed in a child\n",
    "        subsample=0.8,      # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        objective='reg:squarederror'  # Objective function for regression task\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "# Extract values from the second row of master_table\n",
    "length_of_missing_data = pd.Timedelta(master_table.at[1, \"dqDuration\"])\n",
    "data_logging_interval = pd.Timedelta(master_table.at[1, \"pointInterval\"])\n",
    "dqStart = master_table.at[1, \"dqStart\"]\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213e180-a0f5-4c75-9166-03d10b95095c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
