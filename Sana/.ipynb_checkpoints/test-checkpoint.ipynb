{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947eeb87-d2ab-41f9-ad21-b6db7fa9a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n",
      "09:14:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:14:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.503415\n",
      "2023-03-19 01:15:00  22.493035\n",
      "2023-03-19 01:20:00  22.482317\n",
      "2023-03-19 01:25:00  22.471234\n",
      "2023-03-19 01:30:00  22.459765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "def facebook_pred(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Initialize Prophet model with tuned hyperparameters\n",
    "    model_temp = Prophet(seasonality_mode='additive',  # Adjust based on data exploration\n",
    "                         interval_width=0.95,          # Adjust prediction interval if needed\n",
    "                         changepoint_prior_scale=0.01) # Tune based on data patterns\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df)\n",
    "\n",
    "    # Number of predictions\n",
    "    samples = int(length_of_missing_data / data_logging_interval) + 1\n",
    "\n",
    "    # Create future DataFrame\n",
    "    future_temp = model_temp.make_future_dataframe(periods=samples, freq='5T')\n",
    "\n",
    "    # Predict the future values\n",
    "    forecast_temp = model_temp.predict(future_temp)\n",
    "\n",
    "    # Convert dq_start to timezone-naive\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "\n",
    "    # Ensure 'ds' column in forecast_temp is timezone-naive\n",
    "    forecast_temp['ds'] = forecast_temp['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = forecast_temp[forecast_temp['ds'] >= dq_start][['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = facebook_pred(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf2a77f-4e40-41cb-9aa2-694519dc012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.641504\n",
      "2023-03-19 01:15:00  22.641407\n",
      "2023-03-19 01:20:00  22.652977\n",
      "2023-03-19 01:25:00  22.648750\n",
      "2023-03-19 01:30:00  22.621050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    # Initialize XGBoost model\n",
    "    model_temp = xgb.XGBRegressor()\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dddbe6c-7367-4a46-8a38-927ee6b002a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          yhat\n",
      "ds                            \n",
      "2023-03-19 01:10:00  22.747757\n",
      "2023-03-19 01:15:00  22.740808\n",
      "2023-03-19 01:20:00  22.694866\n",
      "2023-03-19 01:25:00  22.684923\n",
      "2023-03-19 01:30:00  22.666439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-03-12 01:05:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    ## Initialize XGBoost model with parameters to reduce noise\n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=100,   # Number of boosting rounds\n",
    "        max_depth=3,        # Maximum depth of each tree\n",
    "        learning_rate=0.1,  # Learning rate\n",
    "        min_child_weight=1, # Minimum sum of instance weight needed in a child\n",
    "        subsample=0.8,      # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        objective='reg:squarederror'  # Objective function for regression task\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b8d1e-2b78-4138-8955-91b4fc4d1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds', 'temp']\n",
    "\n",
    "    # Remove ' Dubai' from the datetime strings\n",
    "    df['ds'] = df['ds'].astype(str).str.replace(' Dubai', '', regex=False)\n",
    "\n",
    "    # Convert the 'ds' column to datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Drop rows where datetime parsing failed\n",
    "    df = df.dropna(subset=['ds'])\n",
    "\n",
    "    # Clean temperature column and convert to numeric\n",
    "    df['temp'] = df['temp'].str.replace('°C', '').astype(float)\n",
    "\n",
    "    # Rename columns for convenience\n",
    "    df.columns = ['ds', 'y']\n",
    "\n",
    "    # Ensure 'ds' column is timezone-naive\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "    dq_start = pd.Timestamp(dqStart, tz='Asia/Dubai').tz_localize(None)\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dq_start + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    # Initialize XGBoost model with parameters to reduce noise\n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=90,   # Number of boosting rounds\n",
    "        max_depth=1,        # Maximum depth of each tree\n",
    "        learning_rate=0.1,  # Learning rate\n",
    "        min_child_weight=1, # Minimum sum of instance weight needed in a child\n",
    "        subsample=0.8,      # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        objective='reg:squarederror'  # Objective function for regression task\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Replace these values with your actual data and variables\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[1, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "length_of_missing_data = pd.Timedelta('0 days 23:30:00')\n",
    "data_logging_interval = pd.Timedelta('0 days 00:05:00')\n",
    "dqStart = '2023-03-19 01:10:00'\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_1(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
