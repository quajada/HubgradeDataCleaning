{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbddfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as n\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from data_extraction.dummy_data_extractor import extract_dummy_data\n",
    "\n",
    "def xgboost_2(df, length_of_missing_data, data_logging_interval, dqStart):\n",
    "  \n",
    "    # Keep only the first two columns\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    df.set_index(df.columns[0], inplace=True, drop=True)\n",
    "    \n",
    "    df = df[df.index < dqStart]\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['ds','y']\n",
    "\n",
    " \n",
    "\n",
    "    # Extract numerical features from datetime\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    df['hour'] = df['ds'].dt.hour\n",
    "    df['minute'] = df['ds'].dt.minute\n",
    "\n",
    "    # Create future DataFrame starting from dq_start\n",
    "    future_periods = int(length_of_missing_data / data_logging_interval) + 1\n",
    "   \n",
    "\n",
    "    future_temp = pd.DataFrame()\n",
    "    future_temp['ds'] = [dqStart + timedelta(minutes=5 * i) for i in range(future_periods)]\n",
    "\n",
    "\n",
    "    # Extract features for XGBoost\n",
    "    future_temp['year'] = future_temp['ds'].dt.year\n",
    "    future_temp['month'] = future_temp['ds'].dt.month\n",
    "    future_temp['day'] = future_temp['ds'].dt.day\n",
    "    future_temp['hour'] = future_temp['ds'].dt.hour\n",
    "    future_temp['minute'] = future_temp['ds'].dt.minute\n",
    "\n",
    "    model_temp = xgb.XGBRegressor(\n",
    "        n_estimators=100,   # Number of boosting rounds\n",
    "        max_depth=3,        # Maximum depth of each tree\n",
    "        learning_rate=0.1,  # Learning rate\n",
    "        min_child_weight=1, # Minimum sum of instance weight needed in a child\n",
    "        subsample=0.8,      # Subsample ratio of the training instances\n",
    "        colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
    "        objective='reg:squarederror'  # Objective function for regression task\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model_temp.fit(df[['year', 'month', 'day', 'hour', 'minute']], df['y'])\n",
    "\n",
    "    # Predict the future values\n",
    "    future_temp['yhat'] = model_temp.predict(future_temp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    # Filter predictions to start from dq_start\n",
    "    predictions = future_temp[['ds', 'yhat']]\n",
    "\n",
    "    # Set 'ds' as the index\n",
    "    predictions.set_index('ds', inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150e575e-9261-4c0e-9b66-b5e566243a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                yhat\n",
      "ds                                  \n",
      "2023-05-09 23:55:00+04:00  15.957184\n",
      "2023-05-10 00:00:00+04:00  17.960670\n",
      "2023-05-10 00:05:00+04:00  18.744310\n",
      "2023-05-10 00:10:00+04:00  17.010210\n",
      "2023-05-10 00:15:00+04:00  16.869192\n",
      "...                              ...\n",
      "2023-05-11 23:40:00+04:00  15.558950\n",
      "2023-05-11 23:45:00+04:00  15.573825\n",
      "2023-05-11 23:50:00+04:00  15.573825\n",
      "2023-05-11 23:55:00+04:00  15.564921\n",
      "2023-05-12 00:00:00+04:00  17.480892\n",
      "\n",
      "[578 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syounas\\OneDrive - Enova Facilities Management\\Tasks\\GitHub\\HubgradeDataCleaning\\Sana\\models\\Final Models\\data_extraction\\dummy_data_extractor.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-05-09 23:55:00+04:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  pythonDF.loc[i, 'dqStart'] = pd.to_datetime(df['ts'].iloc[i], format=\"%Y-%m-%dT%H:%M:%S%z Dubai\")\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "master_table = extract_dummy_data(\"dummy_data\")\n",
    "df = master_table.at[0, \"his\"].iloc[:, :2].copy()\n",
    "\n",
    "# Extract values from the second row of master_table\n",
    "length_of_missing_data = master_table.at[0, \"dqDuration\"]\n",
    "data_logging_interval = master_table.at[0, \"pointInterval\"]\n",
    "dqStart = master_table.at[0, \"dqStart\"]\n",
    "\n",
    "# Call the function\n",
    "predictions = xgboost_2(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cef70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
