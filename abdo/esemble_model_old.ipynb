{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(python_master_table, filter=True):\n",
    "    \"\"\"\n",
    "    Function to run all models, and return the one with lowest RMSE.\n",
    "    Models running through the ensemble model will have input DataFrame (AKA the \"his\" column on master_table) \n",
    "    with timestamp as index, target variable as first column, feature variables as the rest of the columns.\n",
    "\n",
    "    Make sure the output predictions of all models are INCLUSIVE of both the \"start ts\" and \"end ts\" (AKA\n",
    "    last ts with real data before gap, and first ts with real data after gap) \n",
    "\n",
    "    Make sure to follow camelCase for DataFrame column naming for compatibility with SS\n",
    "    \"\"\"\n",
    "\n",
    "    # dictionary to save predictions for each point\n",
    "    scores_df_dict = {\n",
    "    \"pointID\": [],\n",
    "    \"predictions\": [],\n",
    "    \"rmse\": [],\n",
    "    \"modelName\": []\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame from the dictionary\n",
    "    scores_df = pd.DataFrame(scores_df_dict)\n",
    "\n",
    "    for i, row in python_master_table.iterrows():\n",
    "\n",
    "        #-----------------\n",
    "        # INPUTS TO MODELS\n",
    "        #-----------------\n",
    "\n",
    "        pointID = row[\"pointID\"]\n",
    "        df = row[\"his\"]#.to_dataframe()                           #### IMPORTANT : UNCOMMENT THIS ON SS\n",
    "        df.set_index(df.columns[0], inplace=True, drop=True)\n",
    "        length_of_missing_data = row[\"dqDuration\"]\n",
    "        data_logging_interval = row[\"pointInterval\"]\n",
    "        dqStart = row[\"dqStart\"]\n",
    "\n",
    "        #----------------------------\n",
    "        # Dict of Data Quality Models                              ############# ADD NEW MODELS HERE \n",
    "        #----------------------------\n",
    "\n",
    "        # UNIVARIATE Models\n",
    "        dq_models = {\n",
    "            \"Seasonal Naive\" : seasonal_naive,\n",
    "            \"Dynamic Optimized Theta\": dynamic_optimized_theta\n",
    "        }\n",
    "\n",
    "        # # MULTIVARIATE Models using all features to predict target\n",
    "        # dq_models_multivariate = {\n",
    "        #     \"Random Forest Regressor\" : random_Forest_Regressor,\n",
    "        #     \"KNN Regressor Uniform \": kNeighbors_Regressor_Uniform,\n",
    "        #     \"XGBoost 1\": xgboost_1,\n",
    "        #     \"XGboost 2\": xgboost_2,\n",
    "        #     \"XGboost 3\": xgboost_3\n",
    "        # }\n",
    "\n",
    "        # # MULTIVARIATE Models using one feature at a time\n",
    "        # dq_models_multivariate_1feature = {\n",
    "        #     \"Polynomial Regression\" : polynomial_regression,\n",
    "        # }\n",
    "\n",
    "        # if len(df.columns) > 1 ===> use multivariate models dictionary \n",
    "\n",
    "        for model_name, model in dq_models.items():\n",
    "            \n",
    "            #------------------------\n",
    "            # ** Calculating RMSE **\n",
    "            #------------------------\n",
    "\n",
    "            # number of predictions needed\n",
    "            horizon = int(length_of_missing_data/data_logging_interval) +1 # why +1? because if you do length_of_missing_data/data_logging_interval you will get prediction length that is exclusive of the start ts (start ts is the last ts with actual data before the gap), and inclusive of the end ts (end ts is the first ts with actual data after the gap). +1 to get predictions INCLUSIVE of BOTH start and end ts\n",
    "\n",
    "            # training set size (relative to the horizon/prediction size)\n",
    "            training_set_size = horizon * 10\n",
    "\n",
    "            # training / testing set to evaluate the model (relative to horizon of prediction)\n",
    "            train_data = df.iloc[-1*int(training_set_size):-1*int(horizon)]\n",
    "            test_data = df.iloc[-1*int(horizon):]\n",
    "\n",
    "            # the prediction. USED ONLY TO EVALUATE RMSE\n",
    "            predictions_for_rmse = model(train_data, length_of_missing_data, data_logging_interval, dqStart)\n",
    "            rmse_score = mean_squared_error(test_data[test_data.columns[0]].to_numpy(), predictions_for_rmse[predictions_for_rmse.columns[0]].to_numpy(), squared=False)\n",
    "\n",
    "            #------------------\n",
    "            # ** Predictions **\n",
    "            #------------------\n",
    "\n",
    "            # the predictions. USED FOR DATA CLEANING (uses all the data as training)\n",
    "            predictions_for_data_quality = model(df, length_of_missing_data, data_logging_interval, dqStart)\n",
    "\n",
    "            # keep only timestamps for null periods (rows where there are null values on SS)\n",
    "            start = row['dqStart']\n",
    "            duration = row['dqDuration']\n",
    "            interval = row['pointInterval']\n",
    "            timestamps = pd.date_range(start=start, end=start+duration, freq=interval)[1:-1] # clipping the first and last timestamps, as they already exist with actual data on SS\n",
    "\n",
    "            predictions_for_data_quality = predictions_for_data_quality[predictions_for_data_quality.index.isin(timestamps)]\n",
    "\n",
    "            # reset index to make the ts a column instead of index. SS doesnt show the index of a DF\n",
    "            predictions_for_data_quality = predictions_for_data_quality.reset_index()\n",
    "\n",
    "            # rename the ts and predictions column to \"ts\" and \"predictions\", to have similar naming for all ouutputs of models (makes it easier as well when using the dcInsert function on SS.)\n",
    "            predictions_for_data_quality.columns = [\"ts\", \"predictions\"]\n",
    "\n",
    "            # append data to the scores DF\n",
    "            row_to_append = {'pointID': pointID, 'predictions': predictions_for_data_quality, \n",
    "                            \"rmse\": rmse_score, \"modelName\": model_name, \n",
    "                            \"identifier\": \n",
    "                                str(row[\"pointID\"])\n",
    "                                +str(row[\"dqStart\"])\n",
    "                                +str(row[\"dqDuration\"])\n",
    "                                +str(row[\"dqType\"])}\n",
    "            \n",
    "            scores_df = pd.concat([scores_df, pd.DataFrame([row_to_append])], ignore_index=True)\n",
    "\n",
    "            # return predictions with least RMSE for each point/dq issue\n",
    "            idx = scores_df.groupby('identifier')['rmse'].idxmin()\n",
    "            scores_df = scores_df.loc[idx].reset_index(drop=True)\n",
    "            \n",
    "    return scores_df    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
